{
 "cells": [
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T09:02:04.002943Z",
     "iopub.status.busy": "2024-04-29T09:02:04.002496Z",
     "iopub.status.idle": "2024-04-29T09:02:04.007631Z",
     "shell.execute_reply": "2024-04-29T09:02:04.006792Z"
    },
    "papermill": {
     "duration": 0.011169,
     "end_time": "2024-04-29T09:02:04.009566",
     "exception": false,
     "start_time": "2024-04-29T09:02:03.998397",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T03:43:23.705468Z",
     "start_time": "2025-09-02T03:43:23.702208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 设置路径\n",
    "model_path = 'D:/Ti/Py_mmWave_Roformer/rope_informer'\n",
    "processed_data_path = 'D:/Ti/Py_mmWave_Roformer/processed_data'\n",
    "\n",
    "checkpoints = 'D:/Ti/Py_mmWave_Roformer/checkpoints/'\n",
    "output_path = 'D:/Ti/Py_mmWave_Roformer/test_results/'\n",
    "\n",
    "# 确保目录存在\n",
    "os.makedirs(checkpoints, exist_ok=True)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# 将模型路径添加到sys.path\n",
    "sys.path.append(os.path.dirname(model_path))\n",
    "\n",
    "print(\"环境设置完成\")"
   ],
   "id": "7b420ad0ff9e7d15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境设置完成\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-29T09:02:03.300784Z",
     "iopub.status.busy": "2024-04-29T09:02:03.300357Z",
     "iopub.status.idle": "2024-04-29T09:02:03.992361Z",
     "shell.execute_reply": "2024-04-29T09:02:03.991417Z"
    },
    "papermill": {
     "duration": 0.699533,
     "end_time": "2024-04-29T09:02:03.994789",
     "exception": false,
     "start_time": "2024-04-29T09:02:03.295256",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T03:43:23.971174Z",
     "start_time": "2025-09-02T03:43:23.719277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "id": "ec929c6013391808",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T09:02:04.016648Z",
     "iopub.status.busy": "2024-04-29T09:02:04.016404Z",
     "iopub.status.idle": "2024-04-29T09:02:04.020622Z",
     "shell.execute_reply": "2024-04-29T09:02:04.019827Z"
    },
    "papermill": {
     "duration": 0.010161,
     "end_time": "2024-04-29T09:02:04.022744",
     "exception": false,
     "start_time": "2024-04-29T09:02:04.012583",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T03:43:25.519165Z",
     "start_time": "2025-09-02T03:43:23.978689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 为 NumPy 2.0 提供向后兼容性\n",
    "if not hasattr(np, 'Inf'):\n",
    "    np.Inf = np.inf\n",
    "\n",
    "print(\"库导入完成\")"
   ],
   "id": "87ca659205768efb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入完成\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T09:02:20.863301Z",
     "iopub.status.busy": "2024-04-29T09:02:20.862989Z",
     "iopub.status.idle": "2024-04-29T09:02:25.415369Z",
     "shell.execute_reply": "2024-04-29T09:02:25.414561Z"
    },
    "papermill": {
     "duration": 4.561018,
     "end_time": "2024-04-29T09:02:25.417691",
     "exception": false,
     "start_time": "2024-04-29T09:02:20.856673",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T03:43:25.834517Z",
     "start_time": "2025-09-02T03:43:25.823593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载处理好的数据\n",
    "X = np.load(os.path.join(processed_data_path, \"X_test.npy\"))\n",
    "y = np.load(os.path.join(processed_data_path, \"y_test.npy\"))\n",
    "\n",
    "print(f\"加载数据形状: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "\n",
    "# 创建PyTorch数据集\n",
    "class ImageSequenceDataset(Dataset):\n",
    "    \"\"\"图像序列数据集类\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图像序列\n",
    "        sequence = torch.FloatTensor(self.X[idx])\n",
    "        # 获取标签\n",
    "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return sequence, label\n",
    "\n",
    "\n",
    "# 创建完整数据集\n",
    "full_dataset = ImageSequenceDataset(X, y)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 创建子集数据集\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(\"数据加载和预处理完成\")"
   ],
   "id": "d676ab5c5ea98b5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据形状: X=(810, 5, 2, 25, 25), y=(810,)\n",
      "训练集大小: 648\n",
      "测试集大小: 162\n",
      "数据加载和预处理完成\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T09:02:25.429903Z",
     "iopub.status.busy": "2024-04-29T09:02:25.429491Z",
     "iopub.status.idle": "2024-04-29T09:14:18.969650Z",
     "shell.execute_reply": "2024-04-29T09:14:18.968571Z"
    },
    "papermill": {
     "duration": 713.548606,
     "end_time": "2024-04-29T09:14:18.971645",
     "exception": false,
     "start_time": "2024-04-29T09:02:25.423039",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T03:43:26.457673Z",
     "start_time": "2025-09-02T03:43:25.852199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "from rope_informer import Exp_Informer\n",
    "\n",
    "# 自定义实验类，处理图像序列数据\n",
    "class Exp_Informer_Action(Exp_Informer):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Informer_Action, self).__init__(args)\n",
    "        # 修改损失函数为交叉熵\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        \"\"\"获取数据加载器\"\"\"\n",
    "        if flag == 'test':\n",
    "            return test_dataloader\n",
    "        else:\n",
    "            return train_dataloader\n",
    "\n",
    "    def _process_one_batch(self, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "        \"\"\"处理一个批次的数据\"\"\"\n",
    "        # 对于分类任务，我们不需要batch_x_mark和batch_y_mark\n",
    "        # 将数据移动到设备\n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.long().to(self.device)\n",
    "\n",
    "        # 展平图像序列 (batch_size, seq_len, channels, height, width) -> (batch_size, seq_len, channels*height*width)\n",
    "        batch_size, seq_len, channels, height, width = batch_x.shape\n",
    "        batch_x = batch_x.view(batch_size, seq_len, -1)\n",
    "\n",
    "        # 前向传播\n",
    "        if self.args.output_attention:\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "        else:\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = self.criterion(outputs, batch_y)\n",
    "\n",
    "        return outputs, loss\n",
    "\n",
    "print(\"自定义实验类定义完成\")\n",
    "\n",
    "# 设置Informer参数\n",
    "parser = argparse.ArgumentParser(description='[Informer] Action Recognition')\n",
    "\n",
    "# 关键参数修改 - 根据您的数据调整\n",
    "parser.add_argument('--model', type=str, default='informer', help='model of experiment')\n",
    "parser.add_argument('--data', type=str, default='ActionRecognition', help='data name')\n",
    "parser.add_argument('--root_path', type=str, default=processed_data_path, help='root path of the data file')\n",
    "parser.add_argument('--enc_in', type=int, default=1250, help='encoder input size')  # 2*25*25=1250\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')\n",
    "parser.add_argument('--d_ff', type=int, default=256, help='dimension of fcn')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=batch_size, help='batch size of train input data')\n",
    "parser.add_argument('--seq_len', type=int, default=5, help='input sequence length')  # 窗口大小\n",
    "parser.add_argument('--output_path', type=str, default=output_path, help='test_results')\n",
    "parser.add_argument('--checkpoints', type=str, default=checkpoints, help='location of model checkpoints')\n",
    "parser.add_argument('--test_ratio', type=float, default=0.2, help='test ratio')\n",
    "parser.add_argument('--n_heads', type=int, default=4, help='num of heads')\n",
    "parser.add_argument('--has_rope', type=bool, default=True, help='use rope position encoding')\n",
    "\n",
    "# 其他参数\n",
    "parser.add_argument('--data_path', type=str, default='', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M', help='forecasting task')\n",
    "parser.add_argument('--target', type=str, default='', help='target feature')\n",
    "parser.add_argument('--freq', type=str, default='h', help='freq for time features encoding')\n",
    "parser.add_argument('--label_len', type=int, default=3, help='start token length')  # 调整为适合分类任务\n",
    "parser.add_argument('--pred_len', type=int, default=1, help='prediction sequence length')  # 分类任务预测长度为1\n",
    "parser.add_argument('--dec_in', type=int, default=1250, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=5, help='output size')  # 5个类别\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--s_layers', type=str, default='3,2,1', help='num of stack encoder layers')\n",
    "parser.add_argument('--factor', type=int, default=5, help='probsparse attn factor')\n",
    "parser.add_argument('--padding', type=int, default=0, help='padding type')\n",
    "parser.add_argument('--distil', action='store_false', default=True, help='whether to use distilling in encoder')\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--attn', type=str, default='prob', help='attention used in encoder')\n",
    "parser.add_argument('--embed', type=str, default='fixed', help='time features encoding')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "parser.add_argument('--mix', action='store_false', default=True, help='use mix attention in generative decoder')\n",
    "parser.add_argument('--cols', type=str, nargs='+', help='certain cols from the data files as the input features')\n",
    "parser.add_argument('--num_workers', type=int, default=2, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--patience', type=int, default=5, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='cross_entropy', help='loss function')  # 改为交叉熵损失\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', default=False, help='use automatic mixed precision training')\n",
    "parser.add_argument('--inverse', action='store_true', default=False, help='inverse output data')\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', default=False, help='use multiple gpus')\n",
    "parser.add_argument('--devices', type=str, default='0', help='device ids of multile gpus')\n",
    "\n",
    "args = parser.parse_args([])  # 传递空列表避免命令行参数错误\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('实验参数:')\n",
    "for arg in vars(args):\n",
    "    print(f\"  {arg}: {getattr(args, arg)}\")\n",
    "\n",
    "print(\"模型参数配置完成\")"
   ],
   "id": "359e126c9b604750",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自定义实验类定义完成\n",
      "实验参数:\n",
      "  model: informer\n",
      "  data: ActionRecognition\n",
      "  root_path: D:/Ti/Py_mmWave_Roformer/processed_data\n",
      "  enc_in: 1250\n",
      "  d_model: 64\n",
      "  d_ff: 256\n",
      "  train_epochs: 20\n",
      "  batch_size: 16\n",
      "  seq_len: 5\n",
      "  output_path: D:/Ti/Py_mmWave_Roformer/test_results/\n",
      "  checkpoints: D:/Ti/Py_mmWave_Roformer/checkpoints/\n",
      "  test_ratio: 0.2\n",
      "  n_heads: 4\n",
      "  has_rope: True\n",
      "  data_path: \n",
      "  features: M\n",
      "  target: \n",
      "  freq: h\n",
      "  label_len: 3\n",
      "  pred_len: 1\n",
      "  dec_in: 1250\n",
      "  c_out: 5\n",
      "  e_layers: 2\n",
      "  d_layers: 1\n",
      "  s_layers: 3,2,1\n",
      "  factor: 5\n",
      "  padding: 0\n",
      "  distil: True\n",
      "  dropout: 0.05\n",
      "  attn: prob\n",
      "  embed: fixed\n",
      "  activation: gelu\n",
      "  output_attention: False\n",
      "  do_predict: False\n",
      "  mix: True\n",
      "  cols: None\n",
      "  num_workers: 2\n",
      "  itr: 1\n",
      "  patience: 5\n",
      "  learning_rate: 0.0001\n",
      "  des: test\n",
      "  loss: cross_entropy\n",
      "  lradj: type1\n",
      "  use_amp: False\n",
      "  inverse: False\n",
      "  use_gpu: False\n",
      "  gpu: 0\n",
      "  use_multi_gpu: False\n",
      "  devices: 0\n",
      "模型参数配置完成\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "papermill": {
     "duration": 0.007002,
     "end_time": "2024-04-29T09:14:19.451250",
     "exception": false,
     "start_time": "2024-04-29T09:14:19.444248",
     "status": "completed"
    },
    "tags": [],
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-02T03:43:26.463862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置实验\n",
    "\n",
    "torch.manual_seed(111)\n",
    "\n",
    "# 实验设置\n",
    "setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(\n",
    "    args.model, args.data, args.features,\n",
    "    args.seq_len, args.label_len, args.pred_len,\n",
    "    args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor,\n",
    "    args.embed, args.distil, args.mix, args.des, 1)\n",
    "\n",
    "exp = Exp_Informer_Action(args)  # 创建实验实例\n",
    "\n",
    "# 训练模型\n",
    "print('>>>>>>>开始训练: {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "exp.train(setting)\n",
    "\n",
    "print(\"模型训练完成\")"
   ],
   "id": "73f5ae44f7d1b617",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      ">>>>>>>开始训练: informer_ActionRecognition_ftM_sl5_ll3_pl1_dm64_nh4_el2_dl1_df256_atprob_fc5_ebfixed_dtTrue_mxTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 测试模型\n",
    "print('>>>>>>>测试: {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "exp.test(setting)\n",
    "\n",
    "# 清理GPU缓存\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"模型测试完成\")"
   ],
   "id": "bbd3a8ee4e8b165f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载测试结果并可视化\n",
    "# 加载真实标签和预测结果\n",
    "truth = np.load(os.path.join(args.output_path, setting, \"true.npy\"))\n",
    "preds = np.load(os.path.join(args.output_path, setting, \"pred.npy\"))\n",
    "\n",
    "# 计算每个类别的总数和预测正确的数量\n",
    "bin_counts = np.bincount(truth, minlength=5)\n",
    "correct_counts = np.bincount(truth[preds == truth], minlength=5)\n",
    "\n",
    "# 绘制直方图\n",
    "categories = range(5)\n",
    "class_names = ['stationary', 'run', 'squat', 'stand', 'walk']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(categories, bin_counts, width=0.5, align='center', alpha=0.8, label='真实', color='purple')\n",
    "plt.bar(categories, correct_counts, width=0.5, align='edge', alpha=1.0, label='正确', color='lightgreen')\n",
    "\n",
    "# 添加数值标签\n",
    "for i, (bin_count, correct_count) in enumerate(zip(bin_counts, correct_counts)):\n",
    "    plt.text(i, bin_count + 0.1, str(bin_count), ha='center', va='bottom')\n",
    "    plt.text(i, correct_count + 0.1, str(correct_count), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('类别')\n",
    "plt.ylabel('数量')\n",
    "plt.xticks(categories, class_names)\n",
    "plt.legend()\n",
    "plt.title('分类结果统计')\n",
    "\n",
    "# 保存图像\n",
    "plt.savefig('D:/Ti/Py_mmWave_Roformer/classification_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 计算并显示准确率\n",
    "accuracy = np.mean(preds == truth)\n",
    "print(f\"测试准确率: {accuracy:.4f}\")\n",
    "\n",
    "# 计算每个类别的准确率\n",
    "class_accuracies = []\n",
    "for i in range(5):\n",
    "    class_mask = truth == i\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_accuracy = np.mean(preds[class_mask] == truth[class_mask])\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        print(f\"{class_names[i]} 准确率: {class_accuracy:.4f}\")\n",
    "\n",
    "# 绘制类别准确率\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(5), class_accuracies, color='skyblue')\n",
    "plt.xlabel('类别')\n",
    "plt.ylabel('准确率')\n",
    "plt.xticks(range(5), class_names)\n",
    "plt.title('各类别准确率')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, acc in enumerate(class_accuracies):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.savefig('D:/Ti/Py_mmWave_Roformer/class_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"结果可视化和分析完成\")"
   ],
   "id": "5349c91a8c594ceb"
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4892328,
     "sourceId": 8246183,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4902685,
     "sourceId": 8260361,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 741.451527,
   "end_time": "2024-04-29T09:14:21.966849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-29T09:02:00.515322",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
